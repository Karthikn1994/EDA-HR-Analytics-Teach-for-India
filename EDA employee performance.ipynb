{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA) \u2014 Employee Performance\n",
        "\n",
        "This Jupyter Notebook contains step-by-step code to read an employee performance dataset, clean it, explore it, visualize count plots and boxplots, and save a cleaned CSV for modelling. Replace `employee_performance.csv` with your dataset file in the same folder and run all cells (Kernel \u25b6 Restart & Run All)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Load dataset (place your CSV in the same folder and update the filename if needed)\n",
        "DATA_FILE = 'employee_performance.csv'\n",
        "if os.path.exists(DATA_FILE):\n",
        "    df = pd.read_csv(DATA_FILE)\n",
        "    print('Loaded', DATA_FILE)\n",
        "else:\n",
        "    # Create a small sample dataframe scaffold so the notebook runs and demonstrates methods\n",
        "    print('WARNING: employee_performance.csv not found in notebook folder. Creating a small sample dataframe to demonstrate the EDA steps.')\n",
        "    df = pd.DataFrame({\n",
        "        'EmployeeID': [1001,1002,1003,1004,1005],\n",
        "        'Age': [29, 35, 40, 28, 50],\n",
        "        'Gender': ['Male','Female','Male','Female','Male'],\n",
        "        'Department': ['Sales','R&D','R&D','Sales','HR'],\n",
        "        'JobRole': ['Sales Executive','Research Scientist','Laboratory Technician','Sales Executive','HR Manager'],\n",
        "        'MonthlyIncome': [4000, 6500, 3000, 4200, 9000],\n",
        "        'YearsAtCompany': [2, 7, 3, 1, 20],\n",
        "        'OverTime': ['Yes','No','No','Yes','No'],\n",
        "        'JobSatisfaction': [3,4,2,3,4],\n",
        "        'WorkLifeBalance': [2,3,3,2,4],\n",
        "        'PerformanceRating': [3,4,2,3,5]\n",
        "    })\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Quick inspection\n",
        "print('Shape:', df.shape)\n",
        "print('\\nInfo:')\n",
        "print(df.info())\n",
        "print('\\nDescribe:')\n",
        "display(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Missing values and duplicates\n",
        "print('Missing values per column:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print('\\nDuplicate rows:', df.duplicated().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Handling missing values (general approach) - adapt per column as needed\n",
        "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
        "print('Numeric cols:', num_cols)\n",
        "print('Categorical cols:', cat_cols)\n",
        "\n",
        "# Fill numeric with median and categorical with mode (demonstration)\n",
        "for c in num_cols:\n",
        "    if df[c].isnull().any():\n",
        "        df[c].fillna(df[c].median(), inplace=True)\n",
        "for c in cat_cols:\n",
        "    if df[c].isnull().any():\n",
        "        df[c].fillna(df[c].mode().iloc[0], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "print('After cleaning - shape:', df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Drop irrelevant columns example\n",
        "if 'EmployeeID' in df.columns:\n",
        "    df.drop(columns=['EmployeeID'], inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Summary statistics\n",
        "display(df.describe(include='all'))\n",
        "\n",
        "# Unique values for categorical columns\n",
        "for c in cat_cols:\n",
        "    print(f\"{c}: {df[c].nunique()} unique values -> {list(df[c].unique())[:10]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Count plots for key categorical features\n",
        "plt.figure(figsize=(10,6))\n",
        "if 'Department' in df.columns:\n",
        "    sns.countplot(data=df, x='Department', order=df['Department'].value_counts().index)\n",
        "    plt.title('Count of employees by Department')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "if 'JobRole' in df.columns:\n",
        "    sns.countplot(data=df, x='JobRole', order=df['JobRole'].value_counts().index)\n",
        "    plt.title('Count of employees by Job Role')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Boxplots to detect outliers for numeric columns\n",
        "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "for c in num_cols:\n",
        "    plt.figure(figsize=(8,3))\n",
        "    sns.boxplot(x=df[c])\n",
        "    plt.title(f'Boxplot of {c}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Correlation heatmap for numeric features\n",
        "if len(num_cols) > 1:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(df[num_cols].corr(), annot=True, fmt='.2f', cmap='Blues')\n",
        "    plt.title('Correlation Heatmap')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11. Save cleaned dataset\n",
        "CLEAN_FILE = 'clean_employee_performance.csv'\n",
        "df.to_csv(CLEAN_FILE, index=False)\n",
        "print('Saved cleaned dataset as', CLEAN_FILE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next steps (Component 3 - Modelling)\n",
        "\n",
        "1. Feature engineering (create derived features, encode categorical variables)\n",
        "2. Split data into train/test sets and scale features if required\n",
        "3. Train baseline models (Logistic Regression / Random Forest) and evaluate\n",
        "4. Use SHAP/feature importance for explainability\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}